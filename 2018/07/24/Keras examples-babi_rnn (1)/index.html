<!DOCTYPE html>
<html>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8" />

    

    
    <title>Keras examples-babi_rnn | 一只NLPer</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content="深度学习,Keras" />
    
    <meta name="description" content="1  任务描述本实验利用提供的20个种类的数据集，完成KQA的任务。 2 具体实现任务整体流程如图所示： （1）引入必要的包12345678910111213from __future__ import print_functionfrom functools import reduceimport reimport tarfile # 处理压缩文件import numpy as npfrom k">
<meta name="keywords" content="深度学习,Keras">
<meta property="og:type" content="article">
<meta property="og:title" content="Keras examples-babi_rnn">
<meta property="og:url" content="http://yoursite.com/2018/07/24/Keras examples-babi_rnn (1)/index.html">
<meta property="og:site_name" content="一只NLPer">
<meta property="og:description" content="1  任务描述本实验利用提供的20个种类的数据集，完成KQA的任务。 2 具体实现任务整体流程如图所示： （1）引入必要的包12345678910111213from __future__ import print_functionfrom functools import reduceimport reimport tarfile # 处理压缩文件import numpy as npfrom k">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://raw.githubusercontent.com/xiongzongyang/hexo_photo/master/keras02.jpg">
<meta property="og:updated_time" content="2018-07-24T13:41:03.598Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Keras examples-babi_rnn">
<meta name="twitter:description" content="1  任务描述本实验利用提供的20个种类的数据集，完成KQA的任务。 2 具体实现任务整体流程如图所示： （1）引入必要的包12345678910111213from __future__ import print_functionfrom functools import reduceimport reimport tarfile # 处理压缩文件import numpy as npfrom k">
<meta name="twitter:image" content="https://raw.githubusercontent.com/xiongzongyang/hexo_photo/master/keras02.jpg">
    

    

    
        <link rel="icon" href="/css/image/icon.png" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
    
    


</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">好好学习，天天被虐</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Experiment/">Experiment</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Experiment/C/">C++</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Experiment/PHP/">PHP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Experiment/Python/">Python</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Experiment/Scrapy/">Scrapy</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Experiment/leetcode/">leetcode</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/nlp/">nlp</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Material/">Material</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Material/DL/">DL</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Material/ML/">ML</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/Classification/">Classification</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/MDCourse/">MDCourse</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/NLTK/">NLTK</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/Text-similarity/">Text similarity</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NOTES/">NOTES</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NOTES/Chaotic/">Chaotic</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NOTES/Keras/">Keras</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NOTES/Papers/">Papers</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NOTES/Statistical/">Statistical</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NOTES/Tensorflow/">Tensorflow</a></li></ul></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/NOTES/">NOTES</a><i class="icon fa fa-angle-right"></i><a class="page-title-link" href="/categories/NOTES/Keras/">Keras</a>
    </h1>
</div>
                        <div class="main-body-content">
                            <article id="post-Keras examples-babi_rnn (1)" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Keras examples-babi_rnn
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2018/07/24/Keras examples-babi_rnn (1)/" class="article-date">
            <time datetime="2018-07-24T13:29:55.000Z" itemprop="datePublished">2018-07-24</time>
        </a>
    </div>

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/Keras/">Keras</a>, <a class="tag-link" href="/tags/深度学习/">深度学习</a>
    </div>

				<span id="busuanzi_container_page_pv">本文总阅读量<span id="busuanzi_value_page_pv"></span>次</span>
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h2 id="1-任务描述"><a href="#1-任务描述" class="headerlink" title="1  任务描述"></a>1  任务描述</h2><p>本实验利用提供的20个种类的数据集，完成KQA的任务。</p>
<h2 id="2-具体实现"><a href="#2-具体实现" class="headerlink" title="2 具体实现"></a>2 具体实现</h2><p>任务整体流程如图所示：<br><img src="https://raw.githubusercontent.com/xiongzongyang/hexo_photo/master/babi_rnn_1.png" alt="任务整体流程"></p>
<h3 id="（1）引入必要的包"><a href="#（1）引入必要的包" class="headerlink" title="（1）引入必要的包"></a>（1）引入必要的包</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> tarfile <span class="comment"># 处理压缩文件</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">from</span> keras.utils.data_utils <span class="keyword">import</span> get_file</span><br><span class="line"><span class="keyword">from</span> keras.layers.embeddings <span class="keyword">import</span> Embedding</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> recurrent</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br></pre></td></tr></table></figure>
<h3 id="（2）设置一些网络结构常量"><a href="#（2）设置一些网络结构常量" class="headerlink" title="（2）设置一些网络结构常量"></a>（2）设置一些网络结构常量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">RNN=recurrent.LSTM</span><br><span class="line">EMBED_HIDDEN_SIZE=<span class="number">50</span></span><br><span class="line">SENT_HIDDEN_SIZE=<span class="number">100</span></span><br><span class="line">QUERY_HIDDEN_SIZE=<span class="number">100</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">EPOCHS=<span class="number">40</span></span><br><span class="line">print(<span class="string">"RNN/Embed/Sent/Query=&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;"</span>.format(RNN,EMBED_HIDDEN_SIZE,SENT_HIDDEN_SIZE,QUERY_HIDDEN_SIZE))</span><br></pre></td></tr></table></figure>
<h3 id="（3）下载数据集"><a href="#（3）下载数据集" class="headerlink" title="（3）下载数据集"></a>（3）下载数据集</h3><p>数据集的获取，可以直接通过get_file()方法下载，也可以通过<a href="https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz" target="_blank" rel="noopener">https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz</a> 网址提前下载，然后获取文件路径即可。这里对get_file()方法做简单介绍（提前下载好的文件也可以通过该方法来加载）<br><strong>get_file()方法：</strong>从给定的URL中下载文件, 可以传递MD5值用于数据校验(下载后或已经缓存的数据均可)<br><strong>fname:</strong> 文件名，如果指定了绝对路径/path/to/file.txt,则文件将会保存到该位置。<br><strong>origin:</strong> 文件的URL地址<br><strong>返回：</strong>下载后的文件地址<br>关于该方法的更多参数说明：<a href="http://keras-cn.readthedocs.io/en/latest/utils/#get_file" target="_blank" rel="noopener">http://keras-cn.readthedocs.io/en/latest/utils/#get_file</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从网络上获取数据集</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    path = get_file(<span class="string">'babi-tasks-v1-2.tar.gz'</span>,</span><br><span class="line">                    origin=<span class="string">'https://s3.amazonaws.com/text-datasets/'</span></span><br><span class="line">                           <span class="string">'babi_tasks_1-20_v1-2.tar.gz'</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">'Error downloading dataset, please download it manually:\n'</span></span><br><span class="line">          <span class="string">'$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2'</span></span><br><span class="line">          <span class="string">'.tar.gz\n'</span></span><br><span class="line">          <span class="string">'$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz'</span>)</span><br><span class="line">    <span class="keyword">raise</span></span><br></pre></td></tr></table></figure></p>
<p>数据集中一共有20类任务数据，每一类问题又提供了两种不同数量级大小的数据集，1000个问题（默认）和10K个问题，20类问题如下：<br>QA1 - Single Supporting Fact<br>QA2 - Two Supporting Facts<br>QA3 - Three Supporting Facts<br>QA4 - Two Arg. Relations<br>QA5 - Three Arg. Relations<br>QA6 - yes/No Questions<br>QA7 - Counting<br>QA8 - Lists/Sets<br>QA9 - Simple Negation<br>QA10 - Indefinite Knowledge<br>QA11 - Basic Coreference<br>QA12 - Conjunction<br>QA13 - Compound Coreference<br>QA14 - Time Reasoning<br>QA15 - Basic Deduction<br>QA16 - Basic Induction<br>QA17 - Positional Reasoning<br>QA18 - Size Reasoning<br>QA19 - Path Finding<br>QA20 - Agent’s Motivations  </p>
<p>打开某个数据集的txt文件，再来看看具体的数据具体内容：<br>1 John travelled to the hallway.<br>2 Mary journeyed to the bathroom.<br>3 Where is John?     hallway    1<br>4 Daniel went back to the bathroom.<br>5 John moved to the bedroom.<br>6 Where is Mary?     bathroom    2<br>7 John went to the hallway.<br>8 Sandra journeyed to the kitchen.<br>9 Where is Sandra?     kitchen    8<br>10 Sandra travelled to the hallway.<br>11 John went to the garden.<br>12 Where is Sandra?     hallway    10<br>13 Sandra went back to the bathroom.<br>14 Sandra moved to the kitchen.<br>15 Where is Sandra?     kitchen    14<br>这是一个故事的具体内容（长度不一定为15），从中可以看到，每一行数据中包含了编号和文本，而文本可能是陈述句文本（这里记为事实类文本），也可以是“问句\t答案\t支撑答案的行所在编号（可能不止1个）”这种格式的（这里记为问题类文本）。</p>
<h3 id="（4）获取训练集和测试集"><a href="#（4）获取训练集和测试集" class="headerlink" title="（4）获取训练集和测试集"></a>（4）获取训练集和测试集</h3><p>数据集下载下来后可以解压后读入，这里使用的是tarfile模块，linux上常用tarfile模块来处理tar文件，无论tar文件是否被压缩还是仅仅被打包，都可以读取和写入tar文件，这里涉及到的方法为open()和extractfile(),<br>其中：<br><strong>①open()：</strong>除了指出打开文件的方式以外还指出了文件的压缩方式。通过filemode[:compression]的方式可以指出很多种文件模式(比如’r:gz’表示读打开，使用gzip压缩文件)<br><strong>②extractfile()：</strong>从tar包中提取一个子文件，但返回的是个类文件对象，可以通过read，write等方法来操作文件的内容<br>更多资料见：<a href="https://www.cnblogs.com/franknihao/p/6613236.html" target="_blank" rel="noopener">https://www.cnblogs.com/franknihao/p/6613236.html</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造需要的数据集格式</span></span><br><span class="line"><span class="comment"># Default QA1 with 1000 samples</span></span><br><span class="line"><span class="comment"># challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_&#123;&#125;.txt'</span></span><br><span class="line"><span class="comment"># QA1 with 10,000 samples</span></span><br><span class="line"><span class="comment"># challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_&#123;&#125;.txt'</span></span><br><span class="line"><span class="comment"># QA2 with 1000 samples</span></span><br><span class="line">challenge = <span class="string">'tasks_1-20_v1-2/en/qa2_two-supporting-facts_&#123;&#125;.txt'</span></span><br><span class="line"><span class="comment"># QA2 with 10,000 samples</span></span><br><span class="line"><span class="comment"># challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_&#123;&#125;.txt'</span></span><br><span class="line"><span class="keyword">with</span> tarfile.open(path) <span class="keyword">as</span> tar:</span><br><span class="line">    <span class="comment"># 从压缩文件中获取tasks_1-20_v1-2/en/路径下的qa2_two-supporting-facts_train.txt文件，返回的是一个类文件对象，可以通过read，write等方法来操作文件的内容，此处将该对象传递给get_stories()方法</span></span><br><span class="line">    train = get_stories(tar.extractfile(challenge.format(<span class="string">'train'</span>)))</span><br><span class="line">    <span class="comment"># 同理，获取tasks_1-20_v1-2/en/路径下的qa2_two-supporting-facts_train.txt文件</span></span><br><span class="line">    test=get_stories(tar.extractfile(challenge.format(<span class="string">"test"</span>)))</span><br></pre></td></tr></table></figure></p>
<h3 id="（5）数据处理过程中所用到的一些方法"><a href="#（5）数据处理过程中所用到的一些方法" class="headerlink" title="（5）数据处理过程中所用到的一些方法"></a>（5）数据处理过程中所用到的一些方法</h3><p>在获取数据集后，需要将原始数据构建成我们能够使用的数据，其中包括，按照要求构建支撑文本，对支撑文本和问题进行分词，以及向量化操作。</p>
<h4 id="①分词方法"><a href="#①分词方法" class="headerlink" title="①分词方法"></a>①分词方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分词</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(sent)</span>:</span></span><br><span class="line">    <span class="comment"># 返回分词后所形成的列表，保留了标点符号</span></span><br><span class="line">    <span class="comment"># 采用正则来分词，对于正则匹配的每一个字符串，如果该字符串去除左右的空白符以后不为空，则将其保留下来</span></span><br><span class="line">    <span class="keyword">return</span> [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> re.split(<span class="string">"(\w+)?"</span>,sent) <span class="keyword">if</span> x.strip()]</span><br></pre></td></tr></table></figure>
<h4 id="②将原始数据集构建成（story-question-answer）三元组"><a href="#②将原始数据集构建成（story-question-answer）三元组" class="headerlink" title="②将原始数据集构建成（story,question,answer）三元组"></a>②将原始数据集构建成（story,question,answer）三元组</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_stories</span><span class="params">(lines,only_supporting=False)</span>:</span></span><br><span class="line">    data = []</span><br><span class="line">    story = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        <span class="comment"># 对于读入的每一行，将其解码成utf-8格式，并去掉前后空白符</span></span><br><span class="line">        line = line.decode(<span class="string">'utf-8'</span>).strip()</span><br><span class="line">        <span class="comment"># 将该行以空格为分割符进行切割，切割一次，只需要将序号和故事内容分隔开即可。</span></span><br><span class="line">        <span class="comment"># str.split(str="", num=string.count(str)) 其中num指定分割次数</span></span><br><span class="line">        nid, line = line.split(<span class="string">' '</span>, <span class="number">1</span>)</span><br><span class="line">        nid = int(nid)</span><br><span class="line">        <span class="comment"># 如果当前行的编号为1的话，则接下来是一个新故事的开始，首先将当前故事列表清空</span></span><br><span class="line">        <span class="keyword">if</span> nid == <span class="number">1</span>:</span><br><span class="line">            story = []</span><br><span class="line">        <span class="comment"># 如果这一行中包含\t，则说明是问题类文本，处理支撑文本，问题，答案，并将其加入结果list中</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'\t'</span> <span class="keyword">in</span> line:</span><br><span class="line">            <span class="comment"># 将改行文本通过\t分割，分别获取，问题、答案、支撑行编号（可能不止一个）</span></span><br><span class="line">            q, a, supporting = line.split(<span class="string">'\t'</span>)</span><br><span class="line">            <span class="comment"># 将问题分词</span></span><br><span class="line">            q = tokenize(q)</span><br><span class="line">            <span class="comment"># 根据参数选择是否保留其他不相干的文本行</span></span><br><span class="line">            substory = <span class="keyword">None</span></span><br><span class="line">            <span class="keyword">if</span> only_supporting: <span class="comment"># 如果only_supporting为True，则只保留支持答案的哪些文本</span></span><br><span class="line">                <span class="comment"># Only select the related substory</span></span><br><span class="line">                <span class="comment"># 将支撑行编号以空格符分割开，并将每个编号转为为int型</span></span><br><span class="line">                supporting = map(int, supporting.split())</span><br><span class="line">                <span class="comment"># 在遇到问题类文本之前，story会将所有遇到的事实类文本都保留下来，因此，对于每一个支撑行编号，通过story[i-1]即可获取该支撑行文本</span></span><br><span class="line">                substory = [story[i - <span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> supporting]</span><br><span class="line">            <span class="keyword">else</span>: <span class="comment"># 如果是保留全部文本</span></span><br><span class="line">                <span class="comment"># Provide all the substories</span></span><br><span class="line">                <span class="comment"># 将前面所有的事实类文本都保留在substory中，作为支撑文本</span></span><br><span class="line">                substory = [x <span class="keyword">for</span> x <span class="keyword">in</span> story <span class="keyword">if</span> x]</span><br><span class="line">            <span class="comment"># 将处理好的支撑文本，问题，答案加入结果list</span></span><br><span class="line">            data.append((substory, q, a))</span><br><span class="line">            story.append(<span class="string">''</span>)</span><br><span class="line">        <span class="comment"># 如果是事实类文本，则直接分词后加入story列表中，直到遇到问题类文本，取出里面相应的文本，作为支撑文本</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sent = tokenize(line)</span><br><span class="line">            story.append(sent)</span><br><span class="line">    <span class="comment"># data中的数据格式为[(_,_,_)...]</span></span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<h4 id="③获取数据记录"><a href="#③获取数据记录" class="headerlink" title="③获取数据记录"></a>③获取数据记录</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取文本内容函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stories</span><span class="params">(f,only_supporting=False,max_length=None)</span>:</span></span><br><span class="line">    <span class="comment"># 给定文件名，读取这个文件，取回故事，并且将句子转换成单个故事</span></span><br><span class="line">    <span class="comment"># only_supporting参数决定是否只有支持答案的句子被保留下来。</span></span><br><span class="line">    data = parse_stories(f.readlines(), only_supporting=only_supporting)</span><br><span class="line">    <span class="comment"># 创建一个函数</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    reduce() 函数会对参数序列中元素进行累积。</span></span><br><span class="line"><span class="string">    函数将一个数据集合（链表，元组等）中的所有数据进行下列操作：用传给 reduce 中的函数 function（有两个参数）先对集合中</span></span><br><span class="line"><span class="string">    的第 1、2 个元素进行操作，得到的结果再与第三个数据用 function 函数运算，最后得到一个结果。</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 创建一个将支撑材料列表中的元素合并成一个的匿名方法</span></span><br><span class="line">    flatten = <span class="keyword">lambda</span> data: reduce(<span class="keyword">lambda</span> x, y: x + y, data)</span><br><span class="line">    <span class="comment"># 如果没有限制支撑材料的最大长度，或者支撑材料的最大长度小于给定的max_len，于是就将这条记录保留下来</span></span><br><span class="line">    data = [(flatten(story), q, answer) <span class="keyword">for</span> story, q, answer <span class="keyword">in</span> data <span class="keyword">if</span> <span class="keyword">not</span> max_length <span class="keyword">or</span> len(flatten(story)) &lt; max_length]</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<p>其中创建了匿名函数，匿名函数的直观效果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># flatten 方法示例</span></span><br><span class="line">flatten = <span class="keyword">lambda</span> data: reduce(<span class="keyword">lambda</span> x, y: x + y, data)</span><br><span class="line">story=[[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>],[<span class="string">'d'</span>,<span class="string">'e'</span>],[<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="string">'z'</span>]]</span><br><span class="line">flatten(story)</span><br></pre></td></tr></table></figure>
<pre><code>[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;x&#39;, &#39;y&#39;, &#39;z&#39;]
</code></pre><h4 id="④文本向量化方法"><a href="#④文本向量化方法" class="headerlink" title="④文本向量化方法"></a>④文本向量化方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_stories</span><span class="params">(data,word_idx,story_maxlen,query_maxlen)</span>:</span></span><br><span class="line">    xs=[]</span><br><span class="line">    xqs=[]</span><br><span class="line">    ys=[]</span><br><span class="line">    <span class="comment"># 获取每一条记录的支撑材料、问题、答案</span></span><br><span class="line">    <span class="keyword">for</span> story,query,answer <span class="keyword">in</span> data:</span><br><span class="line">        <span class="comment"># 对于支撑材料中的每一个单词，获取其id号，结果得到的是这个支撑文本的序列模型</span></span><br><span class="line">        x=[word_idx[w] <span class="keyword">for</span> w <span class="keyword">in</span> story]</span><br><span class="line">        <span class="comment"># 对于问题中的每一个单词，获取其id号，得到该问题的序列模型</span></span><br><span class="line">        xq=[word_idx[w] <span class="keyword">for</span> w <span class="keyword">in</span> query]</span><br><span class="line">        <span class="comment"># y的维度应该是字典的长度+1，先初试化为0向量</span></span><br><span class="line">        y=np.zeros(len(word_idx)+<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将答案所在的位置的元素值设置为1</span></span><br><span class="line">        y[word_idx[answer]]=<span class="number">1</span></span><br><span class="line">        <span class="comment"># 这条记录的支撑文本序列加入结果集</span></span><br><span class="line">        xs.append(x)</span><br><span class="line">        <span class="comment"># 加入处理后的问题序列</span></span><br><span class="line">        xqs.append(xq)</span><br><span class="line">        <span class="comment"># 加入结果</span></span><br><span class="line">        ys.append(y)</span><br><span class="line">    <span class="comment"># 将支撑文本序列和文本序列填充至最大长度，返回</span></span><br><span class="line">    <span class="keyword">return</span> (pad_sequences(xs,maxlen=story_maxlen),pad_sequences(xqs,maxlen=query_maxlen),np.array(ys))</span><br></pre></td></tr></table></figure>
<h3 id="（6）数据向量化"><a href="#（6）数据向量化" class="headerlink" title="（6）数据向量化"></a>（6）数据向量化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建词汇表   </span></span><br><span class="line">vocab=set()</span><br><span class="line"><span class="comment">## 将所以文本加起来，获取词汇表</span></span><br><span class="line"><span class="keyword">for</span> story,q,answer <span class="keyword">in</span> train+test:</span><br><span class="line">    vocab |=set(story+q+[answer])</span><br><span class="line">vocab=sorted(vocab)</span><br><span class="line"></span><br><span class="line">vocab_size=len(vocab)+<span class="number">1</span></span><br><span class="line"><span class="comment"># 给词汇表中的每个单词建立对应的一个ID号</span></span><br><span class="line">word_idx=dict((c,i+<span class="number">1</span>) <span class="keyword">for</span> i,c <span class="keyword">in</span> enumerate(vocab))</span><br><span class="line">print(word_idx)</span><br></pre></td></tr></table></figure>
<pre><code>{&#39;.&#39;: 1, &#39;?&#39;: 2, &#39;Daniel&#39;: 3, &#39;John&#39;: 4, &#39;Mary&#39;: 5, &#39;Sandra&#39;: 6, &#39;Where&#39;: 7, &#39;apple&#39;: 8, &#39;back&#39;: 9, &#39;bathroom&#39;: 10, &#39;bedroom&#39;: 11, &#39;discarded&#39;: 12, &#39;down&#39;: 13, &#39;dropped&#39;: 14, &#39;football&#39;: 15, &#39;garden&#39;: 16, &#39;got&#39;: 17, &#39;grabbed&#39;: 18, &#39;hallway&#39;: 19, &#39;is&#39;: 20, &#39;journeyed&#39;: 21, &#39;kitchen&#39;: 22, &#39;left&#39;: 23, &#39;milk&#39;: 24, &#39;moved&#39;: 25, &#39;office&#39;: 26, &#39;picked&#39;: 27, &#39;put&#39;: 28, &#39;the&#39;: 29, &#39;there&#39;: 30, &#39;to&#39;: 31, &#39;took&#39;: 32, &#39;travelled&#39;: 33, &#39;up&#39;: 34, &#39;went&#39;: 35}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取支撑材料中单词的最大数目</span></span><br><span class="line">story_maxlen=max(map(len,(x <span class="keyword">for</span> x,_,_ <span class="keyword">in</span> train+test)))</span><br><span class="line"><span class="comment"># 获取问题中单词的最大长度</span></span><br><span class="line">query_maxlen=max(map(len,(x <span class="keyword">for</span> _,x,_ <span class="keyword">in</span> train+test)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别将训练集和测试集中的文本向量化</span></span><br><span class="line">x,xq,y=vectorize_stories(train,word_idx,story_maxlen,query_maxlen)</span><br><span class="line">tx,txq,ty=vectorize_stories(test,word_idx,story_maxlen,query_maxlen)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">"vocab=&#123;&#125;"</span>.format(vocab))</span><br><span class="line">print(<span class="string">"x.shape=&#123;&#125;"</span>.format(x.shape))</span><br><span class="line">print(<span class="string">"xq,shape=&#123;&#125;"</span>.format(xq.shape))</span><br><span class="line">print(<span class="string">"y.shape=&#123;&#125;"</span>.format(y.shape))</span><br><span class="line">print(<span class="string">"story_maxlen,query_maxlen=&#123;&#125;,&#123;&#125;"</span>.format(story_maxlen,query_maxlen))</span><br></pre></td></tr></table></figure>
<pre><code>vocab=[&#39;.&#39;, &#39;?&#39;, &#39;Daniel&#39;, &#39;John&#39;, &#39;Mary&#39;, &#39;Sandra&#39;, &#39;Where&#39;, &#39;apple&#39;, &#39;back&#39;, &#39;bathroom&#39;, &#39;bedroom&#39;, &#39;discarded&#39;, &#39;down&#39;, &#39;dropped&#39;, &#39;football&#39;, &#39;garden&#39;, &#39;got&#39;, &#39;grabbed&#39;, &#39;hallway&#39;, &#39;is&#39;, &#39;journeyed&#39;, &#39;kitchen&#39;, &#39;left&#39;, &#39;milk&#39;, &#39;moved&#39;, &#39;office&#39;, &#39;picked&#39;, &#39;put&#39;, &#39;the&#39;, &#39;there&#39;, &#39;to&#39;, &#39;took&#39;, &#39;travelled&#39;, &#39;up&#39;, &#39;went&#39;]
x.shape=(1000, 552)
xq,shape=(1000, 5)
y.shape=(1000, 36)
story_maxlen,query_maxlen=552,5
</code></pre><p>这里再次用到了RepeatVector，keras.layers.core.RepeatVector(n)：将输入重复n次<br><strong>参数n</strong>：整数，重复的次数<br><strong>输入shape</strong>：形如（nb_samples, features）的2D张量<br><strong>输出shape</strong>：形如（nb_samples, n, features）的3D张量</p>
<h3 id="（7）搭建网络结构"><a href="#（7）搭建网络结构" class="headerlink" title="（7）搭建网络结构"></a>（7）搭建网络结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Build model..."</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个输入层，用于处理的支撑材料文本向量</span></span><br><span class="line">sentence=layers.Input(shape=(story_maxlen,),dtype=<span class="string">"int32"</span>)</span><br><span class="line">encoded_sentence=layers.Embedding(vocab_size,EMBED_HIDDEN_SIZE)(sentence)</span><br><span class="line">encoded_sentence=layers.Dropout(<span class="number">0.3</span>)(encoded_sentence)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二个输入层，用于处理问题文本向量</span></span><br><span class="line">question=layers.Input(shape=(query_maxlen,),dtype=<span class="string">"int32"</span>)</span><br><span class="line">encoded_question=layers.Embedding(vocab_size,EMBED_HIDDEN_SIZE)(question)</span><br><span class="line">encoded_question=layers.Dropout(<span class="number">0.3</span>)(encoded_question)</span><br><span class="line">encoded_question=RNN(EMBED_HIDDEN_SIZE)(encoded_question)</span><br><span class="line"><span class="comment"># 重复向量</span></span><br><span class="line">encoded_question=layers.RepeatVector(story_maxlen)(encoded_question)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将两个经过处理后的输入合并</span></span><br><span class="line">merged=layers.add([encoded_sentence,encoded_question])</span><br><span class="line">merged=RNN(EMBED_HIDDEN_SIZE)(merged)</span><br><span class="line">merged=layers.Dropout(<span class="number">0.3</span>)(merged)</span><br><span class="line">preds=layers.Dense(vocab_size,activation=<span class="string">"softmax"</span>)(merged)</span><br><span class="line"></span><br><span class="line">model=Model([sentence,question],preds)</span><br><span class="line">model.compile(optimizer=<span class="string">"adam"</span>,loss=<span class="string">'categorical_crossentropy'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Training"</span>)</span><br><span class="line">model.fit([x,xq],y,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_split=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">loss,acc=model.evaluate([tx,txq],ty,batch_size=BATCH_SIZE)</span><br><span class="line">print(<span class="string">"Test loss / test accuracy=&#123;:.4f&#125;/&#123;:.4f&#125;"</span>.format(loss,acc))</span><br></pre></td></tr></table></figure>
<pre><code>Build model...
Training
Train on 950 samples, validate on 50 samples
Epoch 1/40
950/950 [==============================] - 10s 11ms/step - loss: 2.9108 - acc: 0.1947 - val_loss: 2.1052 - val_acc: 0.0600
.
.
.
Epoch 40/40
950/950 [==============================] - 10s 10ms/step - loss: 1.6499 - acc: 0.3284 - val_loss: 1.6824 - val_acc: 0.3800
1000/1000 [==============================] - 2s 2ms/step
Test loss / test accuracy=1.7385/0.2640
</code></pre><h3 id="（8）可视化网络结构"><a href="#（8）可视化网络结构" class="headerlink" title="（8）可视化网络结构"></a>（8）可视化网络结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_model(model, to_file=<span class="string">'babi_rnn_model.png'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xiongzongyang/hexo_photo/master/babi_rnn.png" alt="网络结构图"></p>
<h2 id="3-小结"><a href="#3-小结" class="headerlink" title="3 小结"></a>3 小结</h2><p>通过这次实验，收获也是挺多的。首先是数据的处理方式，这里将词汇映射成索引，采用了最基本的python的enumerate方法，对于词汇较少的情况来说非常快，也非常容易上手，此外将词汇映射成id号的方法还有：①利用TensorFlow提供的数据预处理接口；②利用gensim提供的接口建立字典，再将其映射成id号；③利用keras提供的数据预处理接口，同样能将文本映射成id号。接着就是tarfile对压缩文件的操作，由于之前接触linux较少，很多都还是不是很了解，通过这次实验，学到了可以直接处理压缩文件。最后就是，利用keras搭建多输入的网络结构，发现keras真的很方便，网络结构可视化也非常方便（TensorFlow绕来绕去，代码还没敲完，头都晕了_(¦3」∠)_），好啦，就酱！</p>

        </div>
        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>


                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>关注我 :</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/IrvingBei" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/08/16/Keras examples-imdb_bidirectional_lstm (1)/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">下一篇</strong>
        <p class="article-nav-title">
        
            Keras examples-imdb_bidirectional_lstm
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2018/07/21/快速将非数值型目标变量转化为数值型变量/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">上一篇</strong>
        <p class="article-nav-title">快速将非数值型目标变量转化为数值型变量</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/04/11/Beam search 算法的通俗理解/" class="thumbnail">
    
    
        <span style="background-image:url(https://img-blog.csdnimg.cn/20190411204526407.jpg)" alt="Beam search 算法的通俗理解" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NOTES/">NOTES</a></p>
                            <p class="item-title"><a href="/2019/04/11/Beam search 算法的通俗理解/" class="title">Beam search 算法的通俗理解</a></p>
                            <p class="item-date"><time datetime="2019-04-11T13:53:06.000Z" itemprop="datePublished">2019-04-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/04/03/【论文笔记14】Gated-Attention Readers for Text Comprehension/" class="thumbnail">
    
    
        <span style="background-image:url(https://i.imgur.com/YJ7tEYL.png)" alt="【论文笔记14】Gated-Attention Readers for Text Comprehension" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NOTES/">NOTES</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/NOTES/Papers/">Papers</a></p>
                            <p class="item-title"><a href="/2019/04/03/【论文笔记14】Gated-Attention Readers for Text Comprehension/" class="title">【论文笔记14】Gated-Attention Readers for Text Comprehension</a></p>
                            <p class="item-date"><time datetime="2019-04-03T06:30:53.000Z" itemprop="datePublished">2019-04-03</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/04/02/【论文笔记13】Attention-over-Attention Neural Networks for Reading Comprehension/" class="thumbnail">
    
    
        <span style="background-image:url(https://i.imgur.com/A1eLkuS.png)" alt="【论文笔记13】Attention-over-Attention Neural Networks for Reading Comprehension" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NOTES/">NOTES</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/NOTES/Papers/">Papers</a></p>
                            <p class="item-title"><a href="/2019/04/02/【论文笔记13】Attention-over-Attention Neural Networks for Reading Comprehension/" class="title">【论文笔记13】Attention-over-Attention Neural Networks for Reading Comprehension</a></p>
                            <p class="item-date"><time datetime="2019-04-02T08:00:57.000Z" itemprop="datePublished">2019-04-02</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/03/30/【论文笔记12】Iterative Alternating Neural Attention for Machine Reading/" class="thumbnail">
    
    
        <span style="background-image:url(https://i.imgur.com/ClYNuHO.png)" alt="【论文笔记12】Iterative Alternating Neural Attention for Machine Reading" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NOTES/">NOTES</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/NOTES/Papers/">Papers</a></p>
                            <p class="item-title"><a href="/2019/03/30/【论文笔记12】Iterative Alternating Neural Attention for Machine Reading/" class="title">【论文笔记12】Iterative Alternating Neural Attention for Machine Reading</a></p>
                            <p class="item-date"><time datetime="2019-03-30T13:46:43.000Z" itemprop="datePublished">2019-03-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/01/09/Must-read papers on graph neural networks (GNN)/" class="thumbnail">
    
    
        <span style="background-image:url(https://raw.githubusercontent.com/xiongzongyang/hexo_photo/master/d1.jpg)" alt="Must-read papers on GNN" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Material/">Material</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Material/DL/">DL</a></p>
                            <p class="item-title"><a href="/2019/01/09/Must-read papers on graph neural networks (GNN)/" class="title">Must-read papers on GNN</a></p>
                            <p class="item-date"><time datetime="2019-01-09T03:02:49.000Z" itemprop="datePublished">2019-01-09</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">九月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">8</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kaggle/">Kaggle</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keras/">Keras</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLTK基础教程/">NLTK基础教程</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PHP/">PHP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorflow/">Tensorflow</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/">leetcode</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrapy/">scrapy</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分类指标/">分类指标</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/动态注意力/">动态注意力</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/实验教程/">实验教程</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/常见算法/">常见算法</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/搜索算法/">搜索算法</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文本分类/">文本分类</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文本相似度/">文本相似度</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器翻译/">机器翻译</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/混沌神经网络/">混沌神经网络</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/笔记/">笔记</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/自然语言处理/">自然语言处理</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/记忆网络/">记忆网络</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/论文笔记/">论文笔记</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/资料/">资料</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/阅读理解/">阅读理解</a><span class="tag-list-count">9</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/Kaggle/" style="font-size: 12.86px;">Kaggle</a> <a href="/tags/Keras/" style="font-size: 14.29px;">Keras</a> <a href="/tags/NLTK基础教程/" style="font-size: 12.86px;">NLTK基础教程</a> <a href="/tags/PHP/" style="font-size: 10px;">PHP</a> <a href="/tags/Tensorflow/" style="font-size: 10px;">Tensorflow</a> <a href="/tags/leetcode/" style="font-size: 10px;">leetcode</a> <a href="/tags/python/" style="font-size: 14.29px;">python</a> <a href="/tags/scrapy/" style="font-size: 11.43px;">scrapy</a> <a href="/tags/分类指标/" style="font-size: 10px;">分类指标</a> <a href="/tags/动态注意力/" style="font-size: 10px;">动态注意力</a> <a href="/tags/实验教程/" style="font-size: 15.71px;">实验教程</a> <a href="/tags/常见算法/" style="font-size: 10px;">常见算法</a> <a href="/tags/搜索算法/" style="font-size: 10px;">搜索算法</a> <a href="/tags/文本分类/" style="font-size: 14.29px;">文本分类</a> <a href="/tags/文本相似度/" style="font-size: 10px;">文本相似度</a> <a href="/tags/机器学习/" style="font-size: 10px;">机器学习</a> <a href="/tags/机器翻译/" style="font-size: 10px;">机器翻译</a> <a href="/tags/深度学习/" style="font-size: 14.29px;">深度学习</a> <a href="/tags/混沌神经网络/" style="font-size: 10px;">混沌神经网络</a> <a href="/tags/笔记/" style="font-size: 12.86px;">笔记</a> <a href="/tags/自然语言处理/" style="font-size: 17.14px;">自然语言处理</a> <a href="/tags/记忆网络/" style="font-size: 14.29px;">记忆网络</a> <a href="/tags/论文笔记/" style="font-size: 20px;">论文笔记</a> <a href="/tags/资料/" style="font-size: 12.86px;">资料</a> <a href="/tags/阅读理解/" style="font-size: 18.57px;">阅读理解</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="https://blog.csdn.net/xyz1584172808">CSDN</a>
                    </li>
                
                    <li>
                        <a href="http://study.163.com/course/courseMain.htm?courseId=1005638005">Online Course</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2019 IrvingBei</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
				<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
				<span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			</div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'nlper';
    
    
    var disqus_url = 'http://yoursite.com/2018/07/24/Keras examples-babi_rnn (1)/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
